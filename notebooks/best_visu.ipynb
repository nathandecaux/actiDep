{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d7750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110954/3519955667.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['val']=df_filtered['type'].apply(lambda x: x.split('_')[1])\n",
      "/tmp/ipykernel_110954/3519955667.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['type']=df_filtered['type'].apply(lambda x: x.split('_')[0])\n",
      "/tmp/ipykernel_110954/3519955667.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['csv']=df_filtered.apply(lambda row: os.path.join(os.path.dirname(NO_ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.csv\"), axis=1)\n",
      "/tmp/ipykernel_110954/3519955667.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['png']=df_filtered.apply(lambda row: os.path.join(os.path.dirname(NO_ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.png\"), axis=1)\n",
      "/tmp/ipykernel_110954/3519955667.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_acti_filtered['val']=df_acti_filtered['type'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
      "/tmp/ipykernel_110954/3519955667.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_acti_filtered['type']=df_acti_filtered['type'].apply(lambda x: x.split('_')[0])\n",
      "/tmp/ipykernel_110954/3519955667.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_acti_filtered['csv']=df_acti_filtered.apply(lambda row: os.path.join(os.path.dirname(ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.csv\"), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set of group bundles: {'STPOSTCright', 'TPREMleft', 'UFleft', 'CC4', 'CC2', 'STPARleft', 'CC6', 'CC1', 'STPREMleft', 'ORright', 'STPRECright', 'STOCCright', 'TPARright', 'STFOright', 'TPRECleft', 'STPREFright', 'STPARright', 'STRright', 'STPREMright', 'TPREFright', 'POPTright', 'STPOSTCleft', 'STFOleft', 'TPOSTCleft', 'CSTleft', 'CC7', 'STPREFleft', 'TPREMright', 'POPTleft', 'FPTleft', 'TPARleft', 'TPOSTCright', 'STPRECleft', 'TPRECright'}\n",
      "set of psycho bundles: {'STPOSTCright', 'TPREMleft', 'UFleft', 'CC2', 'FPTright', 'CC5', 'STPREMleft', 'STRleft', 'ORright', 'STPRECright', 'MLFleft', 'TPARright', 'STFOright', 'TPRECleft', 'TOCCright', 'STPREFright', 'STPARright', 'STRright', 'TPREFright', 'POPTright', 'STPOSTCleft', 'STFOleft', 'TOCCleft', 'TPOSTCleft', 'STPREFleft', 'TPARleft', 'STPRECleft'}\n",
      "set of apathy bundles: {'STPREMleft', 'MLFright', 'ORright', 'STOCCleft', 'STPOSTCleft', 'CSTright'}\n",
      "set of acti bundles: {'UFright', 'STPOSTCright', 'TPREMleft', 'UFleft', 'CC4', 'CC2', 'FPTright', 'ICPright', 'STPARleft', 'CSTright', 'CC6', 'SCPleft', 'CC1', 'CC5', 'STPREMleft', 'STRleft', 'ORright', 'STPRECright', 'MLFleft', 'STOCCright', 'MCP', 'TPARright', 'STFOright', 'TPRECleft', 'MLFright', 'STPREFright', 'TOCCright', 'STPARright', 'STRright', 'STPREMright', 'TPREFright', 'ICPleft', 'POPTright', 'STPOSTCleft', 'STFOleft', 'CC3', 'ATRleft', 'TOCCleft', 'TPOSTCleft', 'CC7', 'CSTleft', 'STPREFleft', 'TPREMright', 'STOCCleft', 'POPTleft', 'TPREFleft', 'TPARleft', 'TPOSTCright', 'FPTleft', 'STPRECleft', 'TPRECright'}\n",
      "common bundles: {'STPREMleft', 'ORright', 'STPOSTCleft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110954/3519955667.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_acti_filtered['png']=df_acti_filtered.apply(lambda row: os.path.join(os.path.dirname(ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.png\"), axis=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tractviewer import TractViewer\n",
    "from actiDep.data.loader import Actidep\n",
    "from actiDep.set_config import get_HCP_bundle_names\n",
    "NO_ACTI_CSV = \"/home/ndecaux/report_optimized_no_actimetry_clusterFWE/summary_results.csv\"\n",
    "import pandas as pd\n",
    "\n",
    "# Tracts fronto-limbiques MANQUE SLFII\n",
    "fronto_limbiques = [\n",
    "    \"CG_left\", \"CG_right\",\n",
    "    \"UF_left\", \"UF_right\",\n",
    "    \"FX_left\", \"FX_right\",\n",
    "    \"FPT_left\", \"FPT_right\",\n",
    "    \"T_PREF_left\", \"T_PREF_right\",\n",
    "    \"ST_FO_left\", \"ST_FO_right\",\n",
    "    \"ST_PREF_left\", \"ST_PREF_right\"\n",
    "]\n",
    "\n",
    "renaud_dep_controls = ['ATR', 'CC1','SLFI','SLFIII','STPREM', 'UF']\n",
    "renaud_apathy = ['CC1','CC2','CST','SLFIII','STPREM']\n",
    "\n",
    "to_remove = []\n",
    "for b in renaud_dep_controls:\n",
    "    if b+'right' in list(get_HCP_bundle_names().keys()):\n",
    "        renaud_dep_controls.append(b+'left')\n",
    "        renaud_dep_controls.append(b+'right')\n",
    "        to_remove.append(b)\n",
    "\n",
    "renaud_dep_controls= [b for b in renaud_dep_controls if b not in to_remove]\n",
    "\n",
    "for b in renaud_apathy:\n",
    "    if b+'right' in list(get_HCP_bundle_names().keys()):\n",
    "        renaud_apathy.append(b+'left')\n",
    "        renaud_apathy.append(b+'right')\n",
    "        to_remove.append(b)\n",
    "renaud_apathy= [b for b in renaud_apathy if b not in to_remove]\n",
    "\n",
    "# ST_PREM CC2 CC_3\n",
    "# Tracts associés aux émotions\n",
    "emotions = [\n",
    "    \"CG_left\", \"CG_right\",\n",
    "    \"UF_left\", \"UF_right\",\n",
    "    \"FX_left\", \"FX_right\",\n",
    "    \"ATR_left\", \"ATR_right\",\n",
    "    \"CA\",\n",
    "    \"T_PREF_left\", \"T_PREF_right\",\n",
    "    \"ST_FO_left\", \"ST_FO_right\",\n",
    "    \"ST_PREF_left\", \"ST_PREF_right\"\n",
    "]\n",
    "\n",
    "# Tracts moteurs\n",
    "moteurs = [\n",
    "    \"CST_left\", \"CST_right\",\n",
    "    \"CC_3\", \"CC_4\",\n",
    "    \"T_PREM_left\", \"T_PREM_right\",\n",
    "    \"T_PREC_left\", \"T_PREC_right\",\n",
    "    \"T_POSTC_left\", \"T_POSTC_right\",\n",
    "    \"ST_PREM_left\", \"ST_PREM_right\",\n",
    "    \"ST_PREC_left\", \"ST_PREC_right\",\n",
    "    \"ST_POSTC_left\", \"ST_POSTC_right\",\n",
    "    \"ICP_left\", \"ICP_right\",\n",
    "    \"MCP\",\n",
    "    \"SCP_left\", \"SCP_right\"\n",
    "]\n",
    "\n",
    "MIN_SIG = 1\n",
    "MAX_REMOVED_SUBJ = 1\n",
    "MAX_REMOVED_POINTS = 3\n",
    "MIN_CORR = 0.5\n",
    "\n",
    "fronto_limbiques=[b.replace('_','') for b in fronto_limbiques]\n",
    "emotions=[b.replace('_','') for b in emotions]\n",
    "moteurs=[b.replace('_','') for b in moteurs]\n",
    "\n",
    "df=pd.read_csv(NO_ACTI_CSV)\n",
    "filters={\n",
    "    \"fronto_limbiques\": df['bundle'].isin(fronto_limbiques),\n",
    "    \"emotions\": df['bundle'].isin(emotions),\n",
    "    \"moteurs\": df['bundle'].isin(moteurs),\n",
    "    \"significant\": df['n_sig_corrected'] > MIN_SIG-1,\n",
    "    \"all_subs\": df['removed_subjects']<MAX_REMOVED_SUBJ+1,\n",
    "    \"all_points\": df['removed_points']<MAX_REMOVED_POINTS+1,\n",
    "    \"metric\": df['metric'].isin(['FA','IFW','IRF'])\n",
    "}\n",
    "\n",
    "#Application de tous les filtres\n",
    "final_filter = filters[\"significant\"] & filters[\"all_subs\"] & filters[\"all_points\"]# & (filters[\"emotions\"] | filters[\"moteurs\"] | filters[\"fronto_limbiques\"]) & filters[\"metric\"]\n",
    "df_filtered = df[final_filter]\n",
    "df_filtered['val']=df_filtered['type'].apply(lambda x: x.split('_')[1])\n",
    "df_filtered['type']=df_filtered['type'].apply(lambda x: x.split('_')[0])\n",
    "df_filtered['csv']=df_filtered.apply(lambda row: os.path.join(os.path.dirname(NO_ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.csv\"), axis=1)\n",
    "df_filtered['png']=df_filtered.apply(lambda row: os.path.join(os.path.dirname(NO_ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.png\"), axis=1)\n",
    "\n",
    "ACTI_CSV = \"/data/ndecaux/report_actimetry_calcarine/summary_results.csv\"\n",
    "df_acti=pd.read_csv(ACTI_CSV)\n",
    "filters_acti={\n",
    "    \"fronto_limbiques\": df_acti['bundle'].isin(fronto_limbiques),\n",
    "    \"emotions\": df_acti['bundle'].isin(emotions),\n",
    "    \"moteurs\": df_acti['bundle'].isin(moteurs),\n",
    "    \"renaud_dep_controls\": df_acti['bundle'].isin(renaud_dep_controls),\n",
    "    \"renaud_apathy\": df_acti['bundle'].isin(renaud_apathy),\n",
    "    \"significant\": df_acti['n_sig_corrected'] > MIN_SIG-1,\n",
    "    \"all_subs\": df_acti['removed_subjects']<MAX_REMOVED_SUBJ+1,\n",
    "    \"all_points\": df_acti['removed_points']<MAX_REMOVED_POINTS+1,\n",
    "    \"metric\": df_acti['metric'].isin(['FA','IFW','IRF']),\n",
    "    \"min_r\": df_acti['max_abs_r_partial'] > MIN_CORR\n",
    "}\n",
    "final_filter_acti = filters_acti[\"significant\"] & filters_acti[\"all_subs\"] & filters_acti[\"all_points\"]# & filters_acti[\"metric\"] & (filters_acti[\"emotions\"] | filters_acti[\"moteurs\"] | filters_acti[\"fronto_limbiques\"])\n",
    "df_acti_filtered = df_acti[final_filter_acti]\n",
    "df_acti_filtered['val']=df_acti_filtered['type'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "df_acti_filtered['type']=df_acti_filtered['type'].apply(lambda x: x.split('_')[0])\n",
    "df_acti_filtered['csv']=df_acti_filtered.apply(lambda row: os.path.join(os.path.dirname(ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.csv\"), axis=1)\n",
    "df_acti_filtered['png']=df_acti_filtered.apply(lambda row: os.path.join(os.path.dirname(ACTI_CSV), 'figures', f\"{row['bundle']}_{row['metric']}_{row['val']}_{row['type']}_{'corrected' if 'group' in row['type'] else \"partial\"}.png\"), axis=1)\n",
    "\n",
    "df_group = df_filtered[df_filtered['val'] == 'group']\n",
    "df_psycho = df_filtered[df_filtered['type'].str.contains('corr', na=False)]\n",
    "df_apathy = df_filtered[df_filtered['val'] == 'apathy']\n",
    "\n",
    "#Get the bundles that exists in df_group, df_psycho, df_apathy and df_acti_filtered\n",
    "common_bundles = set(df_acti_filtered['bundle']).intersection(set(df_psycho['bundle'])).intersection(set(df_apathy['bundle']))\n",
    "print('set of group bundles:', set(df_group['bundle']))\n",
    "print('set of psycho bundles:', set(df_psycho['bundle']))\n",
    "print('set of apathy bundles:', set(df_apathy['bundle']))\n",
    "print('set of acti bundles:', set(df_acti_filtered['bundle']))\n",
    "print('common bundles:', common_bundles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric FA : min=1000 ; max=-1000\n",
      "Metric IFW : min=1000 ; max=-1000\n",
      "Processing IRF CSTright (1/3)\n",
      "Processing IRF STOCCleft (2/3)\n",
      "Processing IRF STPOSTCleft (3/3)\n",
      "Metric IRF : min=-0.0157698965802659 ; max=0.0247037753286444\n",
      "Metric FA: min=1000 ; max=-1000\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n",
      "Metric IFW: min=1000 ; max=-1000\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n",
      "Metric IRF: min=-0.0157698965802659 ; max=0.0247037753286444\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n",
      "Processing FA STFOleft (1/6)\n",
      "Processing FA STFOright (2/6)\n",
      "Processing FA CC2 (3/6)\n",
      "Processing FA TPREMright (4/6)\n",
      "Processing FA STPREFleft (5/6)\n",
      "Processing FA UFleft (6/6)\n",
      "Metric FA : min=0.0123852400752163 ; max=0.0516068323934183\n",
      "Processing IFW ORright (1/17)\n",
      "Processing IFW FPTleft (2/17)\n",
      "Processing IFW POPTright (3/17)\n",
      "Processing IFW STRright (4/17)\n",
      "Processing IFW CC6 (5/17)\n",
      "Processing IFW STFOleft (6/17)\n",
      "Processing IFW CC4 (7/17)\n",
      "Processing IFW STFOright (8/17)\n",
      "Processing IFW STPREMleft (9/17)\n",
      "Processing IFW STPOSTCright (10/17)\n",
      "Processing IFW STPARright (11/17)\n",
      "Processing IFW TPREMright (12/17)\n",
      "Processing IFW TPARright (13/17)\n",
      "Processing IFW STPREFleft (14/17)\n",
      "Processing IFW STPARleft (15/17)\n",
      "Processing IFW UFleft (16/17)\n",
      "Processing IFW TPARleft (17/17)\n",
      "Metric IFW : min=-0.068044663502549 ; max=-0.0112831454070338\n",
      "Processing IRF CSTleft (1/10)\n",
      "Processing IRF POPTleft (2/10)\n",
      "Processing IRF CC6 (3/10)\n",
      "Processing IRF STFOright (4/10)\n",
      "Processing IRF STPOSTCleft (5/10)\n",
      "Processing IRF STPRECleft (6/10)\n",
      "Processing IRF TPOSTCleft (7/10)\n",
      "Processing IRF STPARleft (8/10)\n",
      "Processing IRF TPRECleft (9/10)\n",
      "Processing IRF TPARleft (10/10)\n",
      "Metric IRF : min=-0.0253812313995723 ; max=0.0359455940013316\n",
      "Metric FA: min=0.0123852400752163 ; max=0.0516068323934183\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n",
      "Metric IFW: min=-0.068044663502549 ; max=-0.0112831454070338\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n",
      "Metric IRF: min=-0.0253812313995723 ; max=0.0359455940013316\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = \"/home/ndecaux/NAS_EMPENN/share/projects/actidep/bids/derivatives/hcp_association_50pts/sub-01002/tracto/sub-01002_bundle-<BUNDLE>_desc-associations_model-MCM_space-HCP_tracto.vtk\"\n",
    "\n",
    "import pyvista\n",
    "import vtk\n",
    "import numpy as np\n",
    "\n",
    "# chosen_csv = \"/home/ndecaux/NAS_EMPENN/share/projects/actidep/prez_seminaire/STPREMleft_FA_ami_corr_partial.csv\"\n",
    "# profile = pd.read_csv(chosen_csv)\n",
    "# profile=profile[profile['sig_afq']]\n",
    "# #Load the tract model\n",
    "# mesh = pyvista.read(model)\n",
    "# # Build mapping from AFQ point index to r value\n",
    "# p2r = dict(zip(profile['point'].astype(int), profile['r'].astype(float)))\n",
    "\n",
    "# # Fetch mesh point indices and convert to int\n",
    "# if 'point_index' not in mesh.point_data:\n",
    "#     raise KeyError(\"Mesh is missing 'point_index' point-data array.\")\n",
    "# pi = np.asarray(mesh.point_data['point_index']).astype(int)\n",
    "# print(p2r)\n",
    "# # Create r array for all mesh points (default 0 when missing)\n",
    "# r_values = np.array([p2r.get(i, 0.0) for i in pi], dtype=float)\n",
    "# # Attach as point data\n",
    "# mesh.point_data['r'] = r_values\n",
    "\n",
    "# #Save as vtk\n",
    "# output_vtk = chosen_csv.replace('.csv', '.vtk')\n",
    "# mesh.save(output_vtk)\n",
    "import json \n",
    "\n",
    "with open('/home/ndecaux/Code/actiDep/bundle_desc_fr.json', encoding='utf-8') as f:\n",
    "    bundle_desc = json.load(f)\n",
    "\n",
    "#Remove _ from bundle_desc keys\n",
    "bundle_desc = {k.replace('_',''): v for k, v in bundle_desc.items()}\n",
    "\n",
    "\n",
    "for type,df_cur in [ ('Psychometry', df_psycho)]:\n",
    "\n",
    "    metric_res={}\n",
    "\n",
    "    for metric in ['FA','IFW','IRF']:\n",
    "        metric_res[metric]={}\n",
    "        df_met=df_cur[df_cur['metric']==metric]\n",
    "        cnt=0\n",
    "        max_met=-1000\n",
    "        min_met=1000\n",
    "        for row in df_met.iterrows():\n",
    "            cnt+=1\n",
    "            # if cnt>1:\n",
    "            #     break\n",
    "            \n",
    "            bundle = row[1]['bundle']\n",
    "            print(f'Processing {metric} {bundle} ({cnt}/{len(df_met)})')\n",
    "            metric_res[metric][bundle]={}\n",
    "            model_b = model.replace('<BUNDLE>', bundle)\n",
    "            mesh = pyvista.read(model_b)\n",
    "            csv=pd.read_csv(row[1]['csv'])\n",
    "\n",
    "            #Get clusters as a list of list of continuous significant points\n",
    "            clusters = []\n",
    "            current_cluster = []\n",
    "            for i, val in enumerate(csv['sig_afq']):\n",
    "                if val:\n",
    "                    current_cluster.append(i)\n",
    "                else:\n",
    "                    if current_cluster:\n",
    "                        clusters.append(current_cluster)\n",
    "                        current_cluster = []\n",
    "            if current_cluster:\n",
    "                clusters.append(current_cluster)\n",
    "            cluster_info = []\n",
    "            for c_idx, c in enumerate(clusters):\n",
    "                mean_p_raw=csv.loc[c, 'p_raw'].mean()\n",
    "                n_points=len(c)\n",
    "                if 'mean_dep' in csv.columns:\n",
    "                    mean_dep=csv.loc[c, 'mean_dep'].mean()\n",
    "                    mean_hc=csv.loc[c, 'mean_hc'].mean()\n",
    "                    std_dep=csv.loc[c, 'std_dep'].mean()\n",
    "                    std_hc=csv.loc[c, 'std_hc'].mean()\n",
    "                    diff_mean=mean_dep-mean_hc\n",
    "                    diff_std=std_dep-std_hc\n",
    "\n",
    "                    text=f'Cluster {c_idx+1} : '\n",
    "                    if diff_mean>0:\n",
    "                        text+=f'HC > DEP ; '\n",
    "                    else:\n",
    "                        text+=f'DEP > HC ; '\n",
    "                    \n",
    "                    if diff_std>0:\n",
    "                        text+=f'STD HC > STD DEP ; '\n",
    "                    else:\n",
    "                        text+=f'STD DEP > STD HC ; '\n",
    "\n",
    "                    text+=f'n={n_points} pts ; p={mean_p_raw:.3f}'\n",
    "                    # cluster_info.append((c[0], c[-1], n_points, mean_p_raw, mean_dep, mean_hc, std_dep, std_hc, diff_mean, diff_std,text))\n",
    "                    cluster_info.append({'start': c[0], 'end': c[-1], 'n_points': n_points, 'mean_p_raw': mean_p_raw, 'mean_dep': mean_dep, 'mean_hc': mean_hc, 'std_dep': std_dep, 'std_hc': std_hc, 'diff_mean': diff_mean, 'diff_std': diff_std, 'text': text})\n",
    "                elif 'mean_1.0' in csv.columns:\n",
    "                    mean_1=csv.loc[c, 'mean_1.0'].mean()\n",
    "                    mean_2=csv.loc[c, 'mean_2.0'].mean()\n",
    "                    std_1=csv.loc[c, 'std_1.0'].mean()\n",
    "                    std_2=csv.loc[c, 'std_2.0'].mean()\n",
    "                    diff_mean=mean_1-mean_2\n",
    "                    diff_std=std_1-std_2\n",
    "                    text=f'Cluster {c_idx+1} : '\n",
    "                    if diff_mean>0:\n",
    "                        text+=f'Groupe 1 > Groupe 2 ; '\n",
    "                    else:\n",
    "                        text+=f'Groupe 2 > Groupe 1 ; '\n",
    "                    if diff_std>0:\n",
    "                        text+=f'STD Groupe 1 > STD Groupe 2 ; '\n",
    "                    else:\n",
    "                        text+=f'STD Groupe 2 > STD Groupe 1 ; '\n",
    "                    \n",
    "                    text+=f'n={n_points} pts ; p={mean_p_raw:.3f}'\n",
    "                    # cluster_info.append((c[0], c[-1], n_points, mean_p_raw, mean_1, mean_2, std_1, std_2, diff_mean, diff_std,text))\n",
    "                    cluster_info.append({'start': c[0], 'end': c[-1], 'n_points': n_points, 'mean_p_raw': mean_p_raw, 'mean_1': mean_1, 'mean_2': mean_2, 'std_1': std_1, 'std_2': std_2, 'diff_mean': diff_mean, 'diff_std': diff_std, 'text': text})\n",
    "                    \n",
    "                else:\n",
    "                    r=csv.loc[c, 'r'].mean()\n",
    "                    text =f'Cluster {c_idx+1} : n={n_points} pts ; p={mean_p_raw:.3f} ; r={r:.3f}'\n",
    "                    # cluster_info.append((c[0], c[-1], n_points, mean_p_raw, r, text))\n",
    "                    cluster_info.append({'start': c[0], 'end': c[-1], 'n_points': n_points, 'mean_p_raw': mean_p_raw, 'r': r, 'text': text})        \n",
    "            \n",
    "            csv=csv[csv['sig_afq']]\n",
    "            if 'r' in csv.columns:\n",
    "                p2r = dict(zip(csv['point'].astype(int), csv['r'].astype(float)))\n",
    "                if csv['r'].max()>max_met:\n",
    "                    max_met=csv['r'].max()\n",
    "                if csv['r'].min()<min_met:\n",
    "                    min_met=csv['r'].min()\n",
    "            else:\n",
    "                p2r = dict(zip(csv['point'].astype(int), csv['diff'].astype(float)))\n",
    "                if csv['diff'].max()>max_met:\n",
    "                    max_met=csv['diff'].max()\n",
    "                if csv['diff'].min()<min_met:\n",
    "                    min_met=csv['diff'].min()\n",
    "            pi = np.asarray(mesh.point_data['point_index']).astype(int)\n",
    "            values=np.array([p2r.get(i, 0.0) for i in pi], dtype=float)\n",
    "            mesh.point_data['stats'] = values\n",
    "\n",
    "            output_vtk = row[1]['csv'].replace('.csv', '.vtk')\n",
    "            mesh.save(output_vtk)\n",
    "            metric_res[metric][bundle]['vtk']=output_vtk\n",
    "            metric_res[metric][bundle]['png']=row[1]['png']\n",
    "            metric_res[metric][bundle]['clusters']=cluster_info\n",
    "            #Sort cluster_info by number of points\n",
    "        \n",
    "        metric_res[metric]['max']=max_met\n",
    "        metric_res[metric]['min']=min_met\n",
    "        print(f'Metric {metric} : min={min_met} ; max={max_met}')\n",
    "    metric_res\n",
    "\n",
    "    from tractviewer import TractViewer\n",
    "    out_dir=f'/home/ndecaux/res_actidep/{type}/'\n",
    "\n",
    "    for metric in metric_res.keys():\n",
    "        out_met=os.path.join(out_dir, metric)\n",
    "        print(f'Metric {metric}: min={metric_res[metric][\"min\"]} ; max={metric_res[metric][\"max\"]}')\n",
    "        min=metric_res[metric][\"min\"]\n",
    "        max=metric_res[metric][\"max\"]\n",
    "        final_text='Métrique '+metric+f' : min={min:.3f} ; max={max:.3f}. Nombre de bundles : {len(metric_res[metric])-2}\\n\\n'\n",
    "        viewer = TractViewer()\n",
    "        \n",
    "        viewer.add_dataset(\n",
    "        \"/home/ndecaux/Code/Data/Atlas/atlas_anat.nii.gz\",\n",
    "            {\n",
    "            \"display_array\": \"intensity\",\n",
    "            \"cmap\": \"gray\",\n",
    "            \"clim\": (200, 800),\n",
    "            \"opacity\": 0.1,\n",
    "            \"ambient\": 0.6,\n",
    "            \"diffuse\": 0.8,\n",
    "            \"specular\": 0.1,\n",
    "            \"scalar_bar\": False,\n",
    "            \"name\": \"anatomy\",\n",
    "            \"style\": \"surface\",\n",
    "        })\n",
    "\n",
    "        for b in [x for x in metric_res[metric].keys() if x not in ['min','max']]:\n",
    "            \n",
    "            final_text+=f'  Bundle {bundle_desc[b]}: clusters:\\n'\n",
    "            for c in metric_res[metric][b]['clusters']:\n",
    "                # print(f\"    - from {c['start']} to {c['end']}: {c['n_points']} pts, p={c['mean_p_raw']:.3f} ; {c['text']}\")\n",
    "                final_text+=f\"    - from {c['start']} to {c['end']}: {c['n_points']} pts, p={c['mean_p_raw']:.3f} ; {c['text']}\\n\"\n",
    "            \n",
    "            #Copy png and vtk to out_met\n",
    "            os.makedirs(out_met, exist_ok=True)\n",
    "            out_png=os.path.join(out_met, os.path.basename(metric_res[metric][b]['png']))\n",
    "            out_vtk=os.path.join(out_met, os.path.basename(metric_res[metric][b]['vtk']))\n",
    "            os.system(f'cp {metric_res[metric][b][\"png\"]} {out_png}')\n",
    "            os.system(f'cp {metric_res[metric][b][\"vtk\"]} {out_vtk}')\n",
    "            metric_res[metric][b]['png']=out_png\n",
    "            metric_res[metric][b]['vtk']=out_vtk\n",
    "\n",
    "            viewer.add_dataset(\n",
    "                metric_res[metric][b]['vtk'],\n",
    "                {\n",
    "                    \"display_array\": \"stats\",\n",
    "                    \"cmap\": \"coolwarm\",\n",
    "                    \"opacity\": 0.8,\n",
    "                    \"ambient\": 0.3,\n",
    "                    \"diffuse\": 0.6,\n",
    "                    \"scalar_bar\": True,\n",
    "                    \"name\": f\"{b}_{metric}\"\n",
    "                }\n",
    "            )\n",
    "        out_gif=os.path.join(out_met, f'{metric}_all_bundles.gif')\n",
    "        viewer.record_rotation(\n",
    "            out_gif,\n",
    "            n_frames=360,      # nombre d'images\n",
    "            step=1.5,          # incrément azimut\n",
    "            elevation=0.0,     # mettre p.ex 10 pour basculer en 1ère moitié puis -10\n",
    "            fps=10,\n",
    "            quality=9,         # (imageio) 0-10\n",
    "            crf=18,            # (si pas de bitrate)\n",
    "            supersample=2,     # rendu interne 2x puis compressé (plus net)\n",
    "            window_size=(600, 400),\n",
    "        )\n",
    "        final_text+=f'\\nAnimation de tous les bundles : {out_gif}\\n'\n",
    "\n",
    "        with open(os.path.join(out_met, 'summary.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(final_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric FA: min=0.0123852400752163 ; max=0.0516068323934183\n",
      "Isosurface extraite (marching_cubes) à 0.200 dans atlas_anat.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: '/home/ndecaux/res_actidep/FA/STFOleft_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/STFOleft_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/STFOleft_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/STFOleft_FA_group_group_corrected.vtk' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/STFOright_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/STFOright_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/STFOright_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/STFOright_FA_group_group_corrected.vtk' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/CC2_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/CC2_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/CC2_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/CC2_FA_group_group_corrected.vtk' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/TPREMright_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/TPREMright_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/TPREMright_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/TPREMright_FA_group_group_corrected.vtk' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/STPREFleft_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/STPREFleft_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/STPREFleft_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/STPREFleft_FA_group_group_corrected.vtk' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/UFleft_FA_group_group_corrected.png' et '/home/ndecaux/res_actidep/FA/UFleft_FA_group_group_corrected.png' identifient le même fichier\n",
      "cp: '/home/ndecaux/res_actidep/FA/UFleft_FA_group_group_corrected.vtk' et '/home/ndecaux/res_actidep/FA/UFleft_FA_group_group_corrected.vtk' identifient le même fichier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
