{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8213066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "src_json = \"/home/ndecaux/NAS_EMPENN/share/projects/actidep/bids/actimetry_feature_descriptions.json\"\n",
    "significant_features = \"global_significant_features.json\"\n",
    "output_json = \"/home/ndecaux/NAS_EMPENN/share/projects/actidep/bids/actimetry_significant_features.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764de738",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23bf71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de features : 41\n",
      "Tâches analysées : ['depressed_vs_control', 'apathy_vs_nonapathy', 'ami', 'aes']\n"
     ]
    }
   ],
   "source": [
    "# Charger les descriptions complètes\n",
    "with open(src_json, 'r') as f:\n",
    "    all_features = json.load(f)\n",
    "\n",
    "# Charger les features significatives\n",
    "with open(significant_features, 'r') as f:\n",
    "    significant_data = json.load(f)\n",
    "\n",
    "print(f\"Nombre total de features : {len(all_features)}\")\n",
    "print(f\"Tâches analysées : {list(significant_data['tasks'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c0e57",
   "metadata": {},
   "source": [
    "# Extraction des features significatives uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887c3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tâche: depressed_vs_control (classification)\n",
      "  Features 12h: 60\n",
      "  Features 3d: 10\n",
      "\n",
      "Tâche: apathy_vs_nonapathy (classification)\n",
      "  Features 12h: 60\n",
      "  Features 3d: 10\n",
      "\n",
      "Tâche: ami (regression)\n",
      "  Features 12h: 6\n",
      "  Features 3d: 3\n",
      "\n",
      "Tâche: aes (regression)\n",
      "  Features 12h: 13\n",
      "  Features 3d: 3\n",
      "\n",
      "Nombre total de features uniques significatives : 30\n",
      "Features : ['activity_max_12h', 'activity_max_3d', 'activity_mean_12h', 'activity_mean_3d', 'activity_min_12h', 'activity_min_3d', 'activity_rate_3d', 'freq_max_12h', 'freq_max_3d', 'freq_mean_12h', 'freq_mean_3d', 'freq_min_12h', 'freq_min_3d', 'freq_std_12h', 'freq_std_3d', 'inactivity_max_12h', 'inactivity_max_3d', 'inactivity_mean_12h', 'inactivity_min_12h', 'inactivity_min_3d', 'inactivity_std_3d', 'oadl_fft_mean_12h', 'oadl_fft_min_12h', 'oadl_min_12h', 'walk_fft_max_12h', 'walk_fft_mean_12h', 'walk_fft_min_12h', 'walk_max_12h', 'walk_mean_12h', 'walk_min_12h']\n"
     ]
    }
   ],
   "source": [
    "# Extraire toutes les features significatives de toutes les tâches\n",
    "all_significant_features = set()\n",
    "\n",
    "for task_name, task_data in significant_data['tasks'].items():\n",
    "    print(f\"\\nTâche: {task_name} ({task_data['type']})\")\n",
    "    \n",
    "    # Features 12h\n",
    "    features_12h = task_data.get('selected_features_12h', [])\n",
    "    print(f\"  Features 12h: {len(features_12h)}\")\n",
    "    \n",
    "    # Features 3d\n",
    "    features_3d = task_data.get('selected_features_3d', [])\n",
    "    print(f\"  Features 3d: {len(features_3d)}\")\n",
    "    \n",
    "    # Ajouter au set (en enlevant le préfixe 'acti_')\n",
    "    for feat in features_12h + features_3d:\n",
    "        # Enlever le préfixe 'acti_'\n",
    "        clean_feat = feat.replace('acti_', '')\n",
    "        \n",
    "        # Pour les features 12h avec suffixe numérique, enlever le suffixe\n",
    "        if '_12h_' in clean_feat:\n",
    "            base_feat = '_'.join(clean_feat.split('_')[:-1])  # Enlever le dernier élément (le numéro)\n",
    "            all_significant_features.add(base_feat)\n",
    "        else:\n",
    "            all_significant_features.add(clean_feat)\n",
    "\n",
    "print(f\"\\nNombre total de features uniques significatives : {len(all_significant_features)}\")\n",
    "print(f\"Features : {sorted(all_significant_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793a95e",
   "metadata": {},
   "source": [
    "# Filtrage du dictionnaire complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd362c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conservé : 2 - inactivity_std_3d\n",
      "✓ Conservé : 3 - inactivity_min_3d\n",
      "✓ Conservé : 4 - inactivity_max_3d\n",
      "✓ Conservé : 5 - activity_mean_3d\n",
      "✓ Conservé : 7 - activity_min_3d\n",
      "✓ Conservé : 8 - activity_max_3d\n",
      "✓ Conservé : 9 - freq_mean_3d\n",
      "✓ Conservé : 10 - freq_std_3d\n",
      "✓ Conservé : 11 - freq_min_3d\n",
      "✓ Conservé : 12 - freq_max_3d\n",
      "✓ Conservé : 13 - activity_rate_3d\n",
      "✓ Conservé : 14 - inactivity_mean_12h\n",
      "✓ Conservé : 16 - inactivity_min_12h\n",
      "✓ Conservé : 17 - inactivity_max_12h\n",
      "✓ Conservé : 18 - activity_mean_12h\n",
      "✓ Conservé : 20 - activity_min_12h\n",
      "✓ Conservé : 21 - activity_max_12h\n",
      "✓ Conservé : 22 - freq_mean_12h\n",
      "✓ Conservé : 23 - freq_std_12h\n",
      "✓ Conservé : 24 - freq_min_12h\n",
      "✓ Conservé : 25 - freq_max_12h\n",
      "✓ Conservé : 26 - walk_mean_12h\n",
      "✓ Conservé : 28 - walk_min_12h\n",
      "✓ Conservé : 29 - walk_max_12h\n",
      "✓ Conservé : 30 - walk_fft_mean_12h\n",
      "✓ Conservé : 32 - walk_fft_min_12h\n",
      "✓ Conservé : 33 - walk_fft_max_12h\n",
      "✓ Conservé : 36 - oadl_min_12h\n",
      "✓ Conservé : 38 - oadl_fft_mean_12h\n",
      "✓ Conservé : 40 - oadl_fft_min_12h\n",
      "\n",
      "Nombre de features dans le JSON filtré : 30\n"
     ]
    }
   ],
   "source": [
    "# Créer un dictionnaire filtré\n",
    "filtered_features = {}\n",
    "\n",
    "for key, feature_data in all_features.items():\n",
    "    feature_name = feature_data['name']\n",
    "    \n",
    "    if feature_name in all_significant_features:\n",
    "        filtered_features[key] = feature_data\n",
    "        print(f\"✓ Conservé : {key} - {feature_name}\")\n",
    "\n",
    "print(f\"\\nNombre de features dans le JSON filtré : {len(filtered_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b36977",
   "metadata": {},
   "source": [
    "# Sauvegarde du JSON filtré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b05d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON filtré sauvegardé dans : /home/ndecaux/NAS_EMPENN/share/projects/actidep/bids/actimetry_significant_features.json\n",
      "Nombre de features conservées : 30\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le JSON filtré\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_features, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON filtré sauvegardé dans : {output_json}\")\n",
    "print(f\"Nombre de features conservées : {len(filtered_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f9eb0",
   "metadata": {},
   "source": [
    "# Statistiques par type de feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8ec087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des features significatives :\n",
      "  Features 3d : 11\n",
      "    - activity_max_3d\n",
      "    - activity_mean_3d\n",
      "    - activity_min_3d\n",
      "    - activity_rate_3d\n",
      "    - freq_max_3d\n",
      "    - freq_mean_3d\n",
      "    - freq_min_3d\n",
      "    - freq_std_3d\n",
      "    - inactivity_max_3d\n",
      "    - inactivity_min_3d\n",
      "    - inactivity_std_3d\n",
      "\n",
      "  Features 12h : 19\n",
      "    - activity_max_12h\n",
      "    - activity_mean_12h\n",
      "    - activity_min_12h\n",
      "    - freq_max_12h\n",
      "    - freq_mean_12h\n",
      "    - freq_min_12h\n",
      "    - freq_std_12h\n",
      "    - inactivity_max_12h\n",
      "    - inactivity_mean_12h\n",
      "    - inactivity_min_12h\n",
      "    - oadl_fft_mean_12h\n",
      "    - oadl_fft_min_12h\n",
      "    - oadl_min_12h\n",
      "    - walk_fft_max_12h\n",
      "    - walk_fft_mean_12h\n",
      "    - walk_fft_min_12h\n",
      "    - walk_max_12h\n",
      "    - walk_mean_12h\n",
      "    - walk_min_12h\n"
     ]
    }
   ],
   "source": [
    "# Analyser les types de features conservées\n",
    "features_by_type = {\n",
    "    '3d': [],\n",
    "    '12h': []\n",
    "}\n",
    "\n",
    "for key, feature_data in filtered_features.items():\n",
    "    feature_name = feature_data['name']\n",
    "    if feature_name.endswith('_3d'):\n",
    "        features_by_type['3d'].append(feature_name)\n",
    "    elif '_12h' in feature_name:\n",
    "        features_by_type['12h'].append(feature_name)\n",
    "\n",
    "print(\"Répartition des features significatives :\")\n",
    "print(f\"  Features 3d : {len(features_by_type['3d'])}\")\n",
    "for feat in sorted(features_by_type['3d']):\n",
    "    print(f\"    - {feat}\")\n",
    "\n",
    "print(f\"\\n  Features 12h : {len(features_by_type['12h'])}\")\n",
    "for feat in sorted(features_by_type['12h']):\n",
    "    print(f\"    - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2088e90",
   "metadata": {},
   "source": [
    "# Groupes de features par préfixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélations attendues pour FA :\n",
      "  Positives (+) :\n",
      "    - activity_mean_3d\n",
      "    - activity_min_3d\n",
      "    - activity_max_3d\n",
      "    - freq_mean_3d\n",
      "    - freq_min_3d\n",
      "    - freq_max_3d\n",
      "    - activity_rate_3d\n",
      "    - activity_mean_12h\n",
      "    - activity_min_12h\n",
      "    - activity_max_12h\n",
      "    - freq_mean_12h\n",
      "    - freq_min_12h\n",
      "    - freq_max_12h\n",
      "    - walk_mean_12h\n",
      "    - walk_min_12h\n",
      "    - walk_max_12h\n",
      "    - walk_fft_mean_12h\n",
      "    - walk_fft_min_12h\n",
      "    - walk_fft_max_12h\n",
      "    - oadl_min_12h\n",
      "    - oadl_fft_mean_12h\n",
      "    - oadl_fft_min_12h\n",
      "\n",
      "  Négatives (-) :\n",
      "    - inactivity_std_3d\n",
      "    - inactivity_min_3d\n",
      "    - inactivity_max_3d\n",
      "    - freq_std_3d\n",
      "    - inactivity_mean_12h\n",
      "    - inactivity_min_12h\n",
      "    - inactivity_max_12h\n",
      "    - freq_std_12h\n",
      "\n",
      "\n",
      "Corrélations attendues pour IFW :\n",
      "  Positives (+) :\n",
      "    - inactivity_std_3d\n",
      "    - inactivity_min_3d\n",
      "    - inactivity_max_3d\n",
      "    - freq_std_3d\n",
      "    - inactivity_mean_12h\n",
      "    - inactivity_min_12h\n",
      "    - inactivity_max_12h\n",
      "    - freq_std_12h\n",
      "\n",
      "  Négatives (-) :\n",
      "    - activity_mean_3d\n",
      "    - activity_min_3d\n",
      "    - activity_max_3d\n",
      "    - freq_mean_3d\n",
      "    - freq_min_3d\n",
      "    - freq_max_3d\n",
      "    - activity_rate_3d\n",
      "    - activity_mean_12h\n",
      "    - activity_min_12h\n",
      "    - activity_max_12h\n",
      "    - freq_mean_12h\n",
      "    - freq_min_12h\n",
      "    - freq_max_12h\n",
      "    - walk_mean_12h\n",
      "    - walk_min_12h\n",
      "    - walk_max_12h\n",
      "    - walk_fft_mean_12h\n",
      "    - walk_fft_min_12h\n",
      "    - walk_fft_max_12h\n",
      "    - oadl_min_12h\n",
      "    - oadl_fft_mean_12h\n",
      "    - oadl_fft_min_12h\n"
     ]
    }
   ],
   "source": [
    "# Grouper les features par préfixe (premier mot)\n",
    "def group_by_prefix(features):\n",
    "    groups = {}\n",
    "    for feat in features:\n",
    "        prefix = feat.split('_')[0]\n",
    "        if prefix not in groups:\n",
    "            groups[prefix] = []\n",
    "        groups[prefix].append(feat)\n",
    "    return groups\n",
    "\n",
    "all_filtered_features = [f['name'] for f in filtered_features.values()]\n",
    "feature_groups = group_by_prefix(all_filtered_features)\n",
    "\n",
    "print(\"Features significatives par groupe :\")\n",
    "for prefix, feats in sorted(feature_groups.items()):\n",
    "    print(f\"\\n{prefix.upper()} ({len(feats)} features):\")\n",
    "    for feat in sorted(feats):\n",
    "        print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0052fe",
   "metadata": {},
   "source": [
    "# Vérification des corrélations attendues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les corrélations attendues par métrique\n",
    "print(\"Corrélations attendues pour FA :\")\n",
    "print(\"  Positives (+) :\")\n",
    "for key, feature_data in filtered_features.items():\n",
    "    if feature_data.get('excepted_correlation', {}).get('FA') == '+':\n",
    "        print(f\"    - {feature_data['name']}\")\n",
    "\n",
    "print(\"\\n  Négatives (-) :\")\n",
    "for key, feature_data in filtered_features.items():\n",
    "    if feature_data.get('excepted_correlation', {}).get('FA') == '-':\n",
    "        print(f\"    - {feature_data['name']}\")\n",
    "\n",
    "print(\"\\n\\nCorrélations attendues pour IFW :\")\n",
    "print(\"  Positives (+) :\")\n",
    "for key, feature_data in filtered_features.items():\n",
    "    if feature_data.get('excepted_correlation', {}).get('IFW') == '+':\n",
    "        print(f\"    - {feature_data['name']}\")\n",
    "\n",
    "print(\"\\n  Négatives (-) :\")\n",
    "for key, feature_data in filtered_features.items():\n",
    "    if feature_data.get('excepted_correlation', {}).get('IFW') == '-':\n",
    "        print(f\"    - {feature_data['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5e444",
   "metadata": {},
   "source": [
    "# Statistiques par groupe et direction de corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f10928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la direction des corrélations par groupe\n",
    "import pandas as pd\n",
    "\n",
    "stats_data = []\n",
    "for prefix, feats in feature_groups.items():\n",
    "    for metric in ['FA', 'IFW']:\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        for feat in feats:\n",
    "            # Trouver la feature dans le dictionnaire filtré\n",
    "            for key, feature_data in filtered_features.items():\n",
    "                if feature_data['name'] == feat:\n",
    "                    expected = feature_data.get('excepted_correlation', {}).get(metric)\n",
    "                    if expected == '+':\n",
    "                        positive += 1\n",
    "                    elif expected == '-':\n",
    "                        negative += 1\n",
    "                    break\n",
    "        \n",
    "        stats_data.append({\n",
    "            'Groupe': prefix,\n",
    "            'Métrique': metric,\n",
    "            'Total': len(feats),\n",
    "            'Corrélation +': positive,\n",
    "            'Corrélation -': negative\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "print(\"\\nStatistiques par groupe et métrique:\")\n",
    "print(stats_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
